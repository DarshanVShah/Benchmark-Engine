"""
Universal TFLite Emotion Classifier Test with Emotion Standardization

This example shows how a user would use the BenchmarkEngine for universal testing
with the integrated emotion standardization system. The engine loads real emotion 
datasets and converts all outputs to standardized, human-readable emotions.
"""

import os
import sys
import numpy as np

# Add the current directory to Python path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from benchmark_datasets.template_dataset import TemplateDataset
from benchmark_datasets.goemotions_dataset import GoEmotionsDataset
from benchmark_datasets.emotion_2018_dataset import Emotion2018Dataset
from core.engine import BenchmarkEngine
from core.emotion_standardization import standardized_emotions
from plugins.tflite_adapter import TensorFlowLiteAdapter
from metrics.template_metric import TemplateMultiLabelMetric


def run_tflite_benchmark():
    """Run the actual TFLite benchmark if model is available."""
    print("=== Running TFLite Benchmark with Emotion Standardization ===\n")
    
    # Check if model file exists
    model_path = "models/notQuantizedModel.tflite"
    if not os.path.exists(model_path):
        print(f"‚ùå TFLite model not found: {model_path}")
        print("   This is expected if you haven't downloaded the model yet.")
        print("   The emotion standardization system is fully functional without the model.")
        return False
    
    # Create the benchmark engine
    engine = BenchmarkEngine()
    
    # Register what we need
    engine.register_adapter("tflite", TensorFlowLiteAdapter)
    engine.register_dataset("template", TemplateDataset)
    engine.register_dataset("GoEmotionsDataset", GoEmotionsDataset)
    engine.register_dataset("Emotion2018Dataset", Emotion2018Dataset)
    
    # Load your TFLite model
    model_config = {
        "device": "cpu",
        "precision": "fp32",
        "max_length": 512,
        "input_type": "text",
        "output_type": "probabilities",
        "task_type": "multi-label",
        "is_multi_label": True
    }
    
    print("Loading TFLite model...")
    if not engine.load_model("tflite", model_path, model_config):
        print("‚ùå Failed to load TFLite model")
        print("   This could be due to:")
        print("   - Missing TensorFlow installation")
        print("   - Corrupted model file")
        print("   - Memory constraints")
        return False
    
    print("‚úÖ TFLite model loaded successfully!")
    
    # Add universal evaluation metric
    universal_metric = TemplateMultiLabelMetric(metric_type="accuracy", threshold=0.5)
    engine.add_metric("universal_accuracy", universal_metric)
    
    # Run universal benchmark (engine loads real datasets)
    print("Running universal benchmark...")
    results = engine.run_universal_benchmark(num_samples=500)
    
    if results:
        print(f"\n‚úÖ Universal benchmark completed successfully!")
        print(f"   Your adapter achieved {results['universal_accuracy']:.1%} average accuracy")
        print(f"   across {results['successful_runs']} successful runs out of {results['datasets_tested']} total datasets.")
        
        if results.get('failed_datasets'):
            print(f"\n   Failed datasets:")
            for failed_dataset in results['failed_datasets']:
                print(f"     - {failed_dataset}")
        
        print(f"\n   Success rate: {results['successful_runs']}/{results['datasets_tested']} = {(results['successful_runs']/results['datasets_tested'])*100:.0f}%")
        
        return True
    else:
        print("‚ùå Benchmark failed")
        return False


def main():
    """Universal test of TFLite emotion classifier with emotion standardization."""
    
    print("TFLite Emotion Classifier with Emotion Standardization")
    print("=" * 60)
    
    # Show emotion standardization info
    print(f"‚úÖ Emotion standardization system ready with {len(standardized_emotions.get_all_emotions())} standardized emotions")
    print(f"‚úÖ Real dataset integration ready")
    print(f"‚úÖ TFLite adapter ready")
    
    # Try to run the actual benchmark
    benchmark_success = run_tflite_benchmark()
    
    if benchmark_success:
        print("\nüéâ Full TFLite benchmark completed successfully!")
    else:
        print("\nüìù Emotion standardization system is fully functional.")
        print("The TFLite benchmark couldn't run, but the core system is ready.")
    
    return benchmark_success


if __name__ == "__main__":
    success = main()
    print("\n" + "="*60)
    print("Emotion Standardization System: READY ‚úÖ")
    print("TFLite Integration: READY ‚úÖ")
    print("Real Dataset Integration: READY ‚úÖ")
